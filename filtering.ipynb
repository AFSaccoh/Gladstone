{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b37811dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c30b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# function to remove duplicates from individual files \n",
    "\n",
    "########################\n",
    "\n",
    "def remove_duplicates(file_path, output_folder):\n",
    "    \"\"\"\n",
    "    Remove duplicates from a CSV file based on the 'ID' column,\n",
    "    keeping the row with the highest 'LOG10P' value. \"\"\"\n",
    "\n",
    "    df=pd.read_csv(file_path)\n",
    "\n",
    "    base = os.path.basename(file_path)  # e.g., 'combined_filtered_aortic_area.csv'\n",
    "    name = base.replace(\"combined_filtered_\", \"\").replace(\".csv\", \"\")\n",
    "    \n",
    "    \n",
    "    filtered_df=df.sort_values('LOG10P', ascending=False).drop_duplicates(subset='ID')\n",
    "    filtered_df.to_csv(os.path.join(output_folder, f\"cleaned_{name}.csv\"), index=False)\n",
    "\n",
    "    print(f'df {name} duplicates removed {df.shape} to {filtered_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f58364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df aortic_area_prepruned duplicates removed (31822, 11) to (16516, 11)\n",
      "df atrial_volume_prepruned duplicates removed (2046, 11) to (1354, 11)\n",
      "df ventrical_volume_prepruned duplicates removed (17237, 11) to (10269, 11)\n",
      "df wall_thickness_prepruned duplicates removed (75925, 11) to (9591, 11)\n",
      "all files saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\" load all trait files and remove duplicates \"\"\"\n",
    "\n",
    "# file1 = \"/Users/adama/Downloads/Tchandjieu_Lab/NMF_python/pre_pruned_files/combined_filtered_aortic_area.csv\"\n",
    "# file2 = \"/Users/adama/Downloads/Tchandjieu_Lab/NMF_python/pre_pruned_files/combined_filtered_atrial_volume.csv\"\n",
    "# file3 = \"/Users/adama/Downloads/Tchandjieu_Lab/NMF_python/pre_pruned_files/combined_filtered_ventrical_volume.csv\"\n",
    "# file4 = \"/Users/adama/Downloads/Tchandjieu_Lab/NMF_python/pre_pruned_files/combined_filtered_wall_thickness.csv\"\n",
    "\n",
    "file1=\"/Users/adama/Downloads/Tchandjieu_Lab/NMF_python/pre_pruned_files/aortic_area_prepruned.csv\"\n",
    "file2=\"/Users/adama/Downloads/Tchandjieu_Lab/NMF_python/pre_pruned_files/atrial_volume_prepruned.csv\"\n",
    "file3=\"/Users/adama/Downloads/Tchandjieu_Lab/NMF_python/pre_pruned_files/ventrical_volume_prepruned.csv\"\n",
    "file4=\"/Users/adama/Downloads/Tchandjieu_Lab/NMF_python/pre_pruned_files/wall_thickness_prepruned.csv\"\n",
    "\n",
    "folder = \"/Users/adama/Downloads/Tchandjieu_Lab/NMF_python/pre_pruned_files/duplicates_removed\"\n",
    "\n",
    "files =[file1, file2, file3, file4]\n",
    "\n",
    "for f in files:\n",
    "    remove_duplicates(f, folder)\n",
    "print('all files saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "234acb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df all_cardiac_traits_prepruned duplicates removed (127030, 11) to (31980, 11)\n"
     ]
    }
   ],
   "source": [
    "combined_path=(f'/Users/adama/Downloads/Tchandjieu_Lab/NMF_python/pre_pruned_files/all_cardiac_traits_prepruned.csv')\n",
    "all_prune= remove_duplicates(combined_path,folder) #not sure about this anymore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c228e91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/adama/Downloads/Tchandjieu_Lab/NMF_python/pre_pruned_files/all_cardiac_traits_prepruned.csv'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0127fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "read=pd.read_csv(\"/Users/adama/Downloads/Tchandjieu_Lab/NMF_python/pre_pruned_files/duplicates_removed/cleaned_all_cardiac_traits_prepruned.csv\")\n",
    "read['p_value']=10 ** (-read['LOG10P'])\n",
    "read.columns\n",
    "combined_final = read[['ID', 'trait', 'p_value','CHROM', 'GENPOS','ALLELE0', 'ALLELE1','A1FREQ','BETA', 'SE']]\n",
    "\n",
    "output_folder=\"/Users/adama/Downloads/Tchandjieu_Lab/NMF_python/pre_pruned_files/duplicates_removed\"\n",
    "\n",
    "output_p = os.path.join(output_folder, f\"cardiac_cardiac_traits_final.csv\")#final file saved here \n",
    "combined_final.to_csv(output_p, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
